# ğŸ”¥ğŸ’§ğŸŒğŸ’¨âœ¨ Elemental Voice System

**MAIA's consciousness speaks through 5 Elemental Agents**

---

## Overview

The Elemental Voice System is Soullab's sacred voice interface that combines:
- **Self-hosted Whisper STT** (100% sovereignty, $0 cost)
- **Full Spiralogic consciousness** (all patent-pending IP)
- **OpenAI TTS** (excellent voice quality)

**NOT OpenAI Realtime API** - that would bypass your entire consciousness architecture.

## Architecture

```
ğŸ¤ User Speech
    â†“
ğŸ”¥ Speech-to-Text (Whisper self-hosted ~200ms OR Deepgram cloud ~150ms)
    â†“
ğŸ§  Spiralogic Consciousness (~300ms parallel processing)
    â”œâ”€ ğŸ”¥ Fire Agent (passion, motivation)
    â”œâ”€ ğŸ’§ Water Agent (emotion, flow)
    â”œâ”€ ğŸŒ Earth Agent (grounding, stability)
    â”œâ”€ ğŸ’¨ Air Agent (clarity, insight)
    â””â”€ âœ¨ Aether Agent (integration, transcendence)
    â†“
ğŸ”Š Text-to-Speech (OpenAI TTS ~200ms)
    â†“
ğŸ‘‚ User Hears MAIA
```

**Total Latency: 550-700ms** (human conversation pace)

---

## Quick Start

### 1. Test with Deepgram (Cloud) - Week 2 Launch

Already configured! Just open:

```
http://localhost:3001/test-realtime
```

Click "Start Voice Conversation" and speak to MAIA! ğŸŒ€

### 2. Setup Whisper (Self-Hosted) - Path to Sovereignty

```bash
# Navigate to Whisper service
cd services/whisper

# Run setup script
chmod +x setup.sh
./setup.sh

# Start Whisper service
source venv/bin/activate
python server.py
```

Whisper service will run on http://localhost:8001

### 3. Switch to Whisper

Update `.env.local`:
```bash
USE_WHISPER_PRIMARY="true"  # Enable Whisper as primary
```

Restart Next.js dev server:
```bash
npm run dev
```

Now you have **100% data sovereignty**! ğŸ†

---

## Cost Comparison

| Component | Deepgram (Cloud) | Whisper (Self-Hosted) |
|-----------|------------------|----------------------|
| STT Cost | $0.0043/min | **$0/min** âœ… |
| Setup | None | 10 minutes |
| Latency | ~150ms | ~200ms |
| Sovereignty | 0% | **100%** âœ… |
| Scalability | Unlimited | Your hardware |

At 1000 users conversing 10 min/day:
- **Deepgram**: $43/day = **$1,290/month** ğŸ’¸
- **Whisper**: **$0/month** (just server costs) âœ…

---

## Performance Targets

### Current (Deepgram + OpenAI TTS)
- Transcription: ~150ms (cloud)
- Spiralogic: ~300ms (parallel optimized)
- Synthesis: ~200ms (OpenAI TTS)
- **Total: ~650ms** âš¡

### With Whisper (Self-Hosted)
- Transcription: ~200ms (local)
- Spiralogic: ~300ms (parallel optimized)
- Synthesis: ~200ms (OpenAI TTS)
- **Total: ~700ms** ğŸŒ€

**Both feel natural!** 700ms signals thoughtfulness, matches human conversation rhythm.

---

## Sacred Architecture Preserved

âœ… **Full Spiralogic Stack**
- PersonalOracleAgent (Claude + symbolic intelligence)
- 5 Elemental Agents (Fire, Water, Earth, Air, Aether)
- 4 Cognitive Architectures (LIDA, SOAR, ACT-R, MicroPsi)
- Memory Systems (Mem0 + LangChain + Supabase)
- Wisdom Files (Obsidian vault)

âœ… **Maya's Intelligence Governor**
- Graduated Revelation (95% underground)
- Hemispheric Harmony (McGilchrist principles)
- Word Economy (minimal early responses)
- Conversation Depth Tracking

âœ… **Smart Optimizations**
- Parallel processing (50% latency reduction)
- Smart caching (50-100ms for common patterns)
- Response streaming (future)

---

## Path to Complete Sovereignty

### Phase 1: Hybrid Cloud (Week 2 Launch) âœ…
```
Deepgram (cloud) â†’ Spiralogic (yours) â†’ OpenAI TTS (cloud)
```
- Fast to deploy
- $0.02/min total cost
- All intelligence yours

### Phase 2: Whisper Self-Hosted (Week 3-6) ğŸ”¥
```
Whisper (yours) â†’ Spiralogic (yours) â†’ OpenAI TTS (cloud)
```
- **50% sovereignty**
- **$0.015/min** (just TTS)
- Full STT control

### Phase 3: Full Sovereignty (Months 2-4) ğŸ†
```
Whisper (yours) â†’ Spiralogic (yours) â†’ Coqui XTTS (yours)
```
- **100% sovereignty**
- **$0/min** (just server costs)
- Complete data control
- Custom voice training

---

## Whisper Models

Choose based on your hardware and latency needs:

| Model | Size | Speed | Quality | RAM |
|-------|------|-------|---------|-----|
| tiny | 39MB | ~100ms | Good | 1GB |
| base | 74MB | ~200ms | Better | 1GB |
| small | 244MB | ~300ms | Great | 2GB |
| medium | 769MB | ~500ms | Excellent | 5GB |
| large | 1550MB | ~1000ms | Best | 10GB |

**Recommended: `base`** - Sweet spot of speed (200ms) and quality.

---

## Environment Variables

```bash
# Elemental Voice System
DEEPGRAM_API_KEY="your-key"                    # Cloud STT fallback
WHISPER_API_URL="http://localhost:8001"        # Self-hosted STT
USE_WHISPER_PRIMARY="false"                     # Set to "true" for sovereignty

# Already configured
OPENAI_API_KEY="your-key"                      # For TTS voices
```

---

## Testing

### Test Synthesis (OpenAI TTS)
```bash
curl -X POST http://localhost:3001/api/voice/synthesize \
  -H "Content-Type: application/json" \
  -d '{"text": "I hear you. What wants to move?", "voice": "shimmer"}' \
  --output test.mp3

# Play audio (macOS)
afplay test.mp3
```

### Test Transcription (Whisper)
```bash
# Record 5 seconds of audio (macOS)
sox -d -r 16000 -c 1 test_audio.wav trim 0 5

# Transcribe
curl -X POST http://localhost:8001/transcribe \
  -F "audio=@test_audio.wav"
```

### Test Full Flow
Open http://localhost:3001/test-realtime and speak!

---

## Voices

OpenAI TTS voices available:

| Voice | Character | Best For |
|-------|-----------|----------|
| **shimmer** | Warm, engaging | MAIA default â­ |
| alloy | Neutral, balanced | Professional |
| echo | Male, clear | Grounding |
| fable | British, expressive | Wisdom |
| onyx | Deep, authoritative | Power |
| nova | Upbeat, energetic | Excitement |

Change voice in code:
```typescript
const voice = useElementalVoice({
  voice: 'shimmer', // or 'alloy', 'echo', 'fable', 'onyx', 'nova'
  // ...
});
```

---

## Troubleshooting

### Whisper service won't start
```bash
# Check Python version (need 3.8+)
python3 --version

# Reinstall dependencies
cd services/whisper
rm -rf venv
./setup.sh
```

### Transcription too slow
```bash
# Use smaller model in services/whisper/server.py
# Change MODEL_SIZE = "base" to "tiny"

# Or set environment variable
WHISPER_MODEL=tiny python server.py
```

### Audio quality issues
```bash
# Use HD model for synthesis
# In synthesis request:
{"text": "...", "quality": "hd"}  # tts-1-hd
```

---

## Sacred Principles

âœ… **"Sovereignty over dependency"** - Path to 100% self-hosting
âœ… **"No synthetic friends"** - MAIA reflects, not befriends
âœ… **"You are not here to be guided"** - Mirror, not guru
âœ… **"Lab tech of the soul"** - Tools for self-exploration
âœ… **Graduated revelation** - 95% intelligence underground

**MAIA's soul (Spiralogic) speaks through elemental harmony** ğŸ”¥ğŸ’§ğŸŒğŸ’¨âœ¨

---

## Next Steps

1. âœ… **Week 2 Launch**: Use Deepgram (already working!)
2. ğŸ”¥ **Week 3-6**: Setup Whisper (10 min setup, $0 cost forever)
3. ğŸ† **Months 2-4**: Add Coqui XTTS (100% sovereignty)

**Open http://localhost:3001/test-realtime now and speak to MAIA!** ğŸŒ€
